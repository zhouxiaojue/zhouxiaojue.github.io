[{"authors":null,"categories":null,"content":"I am currently a graduate student at University of California, Irvine working at visual perception and neuroimaging lab (VPNL) with Prof. Emily Grossman. My main research interest is to how we understand someone else\u0026rsquo;s action in a complex social environment through modeling action perception using fMRI data. I model fMRI data with tools such as machine learning and statistical models.\nDuring spare time, I have a lot of interests. Recently I am trying to make a perfectly sweet espresso and become Ping Pong master in VR.\n","date":1638316800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1638316800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am currently a graduate student at University of California, Irvine working at visual perception and neuroimaging lab (VPNL) with Prof. Emily Grossman. My main research interest is to how we understand someone else\u0026rsquo;s action in a complex social environment through modeling action perception using fMRI data.","tags":null,"title":"Xiaojue Zhou","type":"authors"},{"authors":["Xiaojue Zhou","Emily Grossman"],"categories":null,"content":"","date":1638316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638316800,"objectID":"c1263085bcb1f5169dc2c2d555575dc4","permalink":"https://zhouxiaojue.github.io/publication/litreview_2020_2/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/litreview_2020_2/","section":"publication","summary":"","tags":null,"title":"Where Are Our Action Predictions? Action Understanding as a Predictive Process: Integrative Model and Neuroimage Evidence","type":"publication"},{"authors":["Derderian, K","Zhou, X","Chen, L"],"categories":null,"content":"","date":1638316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638316800,"objectID":"a7b85fb883f17f698d9ec843a5a40934","permalink":"https://zhouxiaojue.github.io/publication/metaanalysis2020_2/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/metaanalysis2020_2/","section":"publication","summary":"The cortical organization of the semantic network has been studied extensively in neuropsychological and neuroimaging studies. Recent theories have heavily relied on the observation of category-specific activations, i.e., the preferential activations in brain regions for specific semantic categories. With decades of research, a full understanding of the organization has not yet been reached, since little is known about the factors that contribute to the variances in observed activation patterns across numerous neuroimaging studies. In this study, we first reviewed 97 published papers that reported category-specific activations for living or nonliving concepts in the past two decades. Then, using the Activation Likelihood Estimate (ALE) method, we characterized the brain activation associated with living and nonliving concepts, revealing the influences of relevant factors (e.g., neuroimaging mode, task demands, and stimuli modality), and analyzing these findings in relation to theoretical accounts of cortical semantic networks.","tags":null,"title":"Where for what: A meta-analysis for the category-specific activations for living/nonliving concepts in the past two decades","type":"publication"},{"authors":["Xiaojue Zhou"],"categories":["Imaging Analysis","tutorial"],"content":"","date":1607715565,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607715565,"objectID":"2eb425f7265ebe226cdcb84f91279f4c","permalink":"https://zhouxiaojue.github.io/post/imageorientation/","publishdate":"2020-12-11T11:39:25-08:00","relpermalink":"/post/imageorientation/","section":"post","summary":"So your neuroimage data somehow is flipped, what do you do?","tags":["Imaging Analysis","nifti","Brain Voyager","afni","FSL","freesurfer"],"title":"Neuroimage format and orientation information in nifti","type":"post"},{"authors":["Xiaojue Zhou","Emily Grossman"],"categories":null,"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"cbba2190022eef306e7cdd59f8d4aaa8","permalink":"https://zhouxiaojue.github.io/publication/ifg2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/ifg2021/","section":"publication","summary":"","tags":null,"title":"Sensory and Social Cognitive Networks Connectivity Depends on Attentive States.","type":"publication"},{"authors":["Daniel Stehr","Xiaojue Zhou","Mariel Tisby","Patrick Hwu","John Pyles","Emily Grossman"],"categories":null,"content":"","date":1606780800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606780800,"objectID":"856dc3b3c3b856e9ab877a5fddd0553e","permalink":"https://zhouxiaojue.github.io/publication/mvpa2020_2/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/mvpa2020_2/","section":"publication","summary":"To test for the influence of top-down influences on action perceptual encoding, we evaluated the statistical structure of the multivariate activation pattern from the pSTS while observers attended to the different dimensions (the action kinematics, the goal, or the identity) of an avatar engaged in two different actions. Multivariate pattern decoding accuracy varied as a function of attention instruction in the right pSTS, but not in the other regions of the AON, with the highest classification when observers attended to the action kinematics. Furthermore, functional connectivity between the pSTS and inferior frontal cortex (IFC) was stronger when observers attended to the actions portrayed in the vignettes. Our findings are evidence that the attention goals of the viewer modulate sensory representations in the pSTS, which is proposals of the pSTS as an interstitial zone mediating top-down context and bottom-up perceptual cues during action observation.","tags":null,"title":"Top-down attention guidance shapes action encoding in the pSTS","type":"publication"},{"authors":["Xiaojue Zhou"],"categories":["tutorial","Imaging Analysis"],"content":"Understanding Surface Preprocessing in Brain Voyager Surface reconstruction in freesurfer Surface group normalization (CBA alignment in BV) Move functional data to native surface (BV) Move functional data to reference surface (BV) Move volumetric ROI (VOI) to surface ROI (POI) (BV) Calculate functional connectivity in MATLAB Export functional connectivity map to surface statistical maps for visualization (BV) Non-parametric testing for thresholding whole brain connectivity analysis More Coming\u0026hellip;\n","date":1605830400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607644800,"objectID":"6fd6c71c1b3cdfeda2895f4a76798feb","permalink":"https://zhouxiaojue.github.io/post/bvsurface/","publishdate":"2020-11-20T00:00:00Z","relpermalink":"/post/bvsurface/","section":"post","summary":"Using Brain Voyager and MATLAB to do a computaionally efficient and intuitive surface analysis","tags":["Brain Voyager","Surface Analysis","freesurfer"],"title":"How to do surface functional connectivity analysis?","type":"post"},{"authors":["Xiaojue Zhou","Priyam Das","Jinwei Xing"],"categories":["Machine Learning"],"content":"Purpose Our group chose to work with the Diabetes 130-US Hospitals dataset for this project. This dataset contains 10 years of patient diabetes records collected from 130 hospitals in the US. The dataset contains\n 101,766 records 49 features 3 class labels. A description of the features and the amount of missing data in each category can be found at https://www.hindawi.com/journals/bmri/2014/781670/tab1/ so we will not spend time explaining them here.  What we are predicting The 3 class labels our models will predict are We are trying to understand the diabete\u0026rsquo;s readmission rates in relationship to other variables. Specifically, re-admission rates referred to whether or not a patient is readmitted to the hospital after the visit recorded in the database.\n \u0026ldquo;\u0026lt;30\u0026rdquo; : whether the patient was readmitted in less than 30 days \u0026ldquo;\u0026gt;30\u0026rdquo; : whether the patient was readmitted in more than 30 days \u0026ldquo;NO\u0026rdquo; : no record of readmission exists  Cleaning the Data and Feature Selection Missing Data First we looked at those features with high amounts of missing data:\n weight (97% missing, will fit model with and without) payer code (not relevant for diabetes itself but maybe interesting to look in the future) medical specialty (53% missing)  We found out 97% of the weight data was missing so then we decided there was no worth in trying to include it in our analyses. We also threw out the payer code feature because the type of health insurance a patient has should have very little bearing on a patient’s care and whether they will be readmitted. We went back and forth on whether to keep medical specialty - which is a feature describing the speciality of the attending doctor. 53% of the data was missing in this category. After inspecting the values this feature could take on (84 distinct values in total) we decided it was out of scope for the project to try and reconstruct the missing values and also decided to exclude this feature from our final analyses.\nWe also delete these empty features:\n examide: No patients were prescribed this drug citoglipton: No patients were prescribed this drug  Also, we deleted these features with less than 2 inputs\n glimepiride pioglitazone acetohexamide metformin.pioglitazone metformin.rosiglitazone  Transform Data Comorbidity:\nThe ICD-9 codes that were used as values for diag1, diag2, and diag3 (diagnoses) were remapped to 9 categorical values that indicated the type of disease:\n Circulatory Respiratory Digestive Diabetes Injury Musculoskeletal Genitourinary Neoplasms Other  Multiple visits: Finally, we noticed that some patient identifying numbers were repeated more than once, indicating multiple visits from the same person. In order to be able to assume independence of our data points, we only kept the first visit (as identified using encounter ids) for each patient and threw out the rest.\nCleaned Dataset Out final cleaned dataset:\n number of data points: 71,518 rows number of features: 38 columns  Exploratory Data Analysis PCA In an attempt to reduce the number of features further, we performed a principal components analysis (PCA) but this did not prove too informative. The first principal component only accounted for 5.5% of the data. Therefore we decided to keep the rest of our features. Figure 1 shows how much each feature explains the data set. The features making the most contributions are indicator variables that say whether or not diabetes medication was prescribed to the patient and whether or not there was a change in dosage for prescribed medication. These features together accounted for 10% of the data. Whether diabetes medication was prescribed and whether there was a change are highly correlated. We suspect this may be because if a patient’s condition is worsening, then a new medication may be prescribed or a higher dosage given and thus there will be a change in dosage. Alternatively, if a patient’s condition is improving, their dosage may be decreased and this is still a change. If someone is not prescribed medicine at all, then there will be no change to administer.\nFigure 1. Principal components of the data and how much each accounted for the data.\nLogistic Regression We performed some additional preprocessing of the data, namely one-hot encoding the categorical values and shuffling the data. with larger values as more important. After the one-hot encoding, there are 73 features to be used as coefficients in our model.\nThe data was also split into a training set and a test set, with the first 60,000 data points used for the training set. We trained a multiclass logistic regression model using scikit-learn. Since there are 3 classes, we trained 3 binary classifiers.\nThe accuracy on the test data was 0.609. Additionally, we report the features that had the highest abstract coefficients for each classifier.\n\u0026lt; 30 class (readmitted within 30 days) The most important factors were:\n number of inpatient (β = 3.899) emergency (β = 1.962) visits, the prescription of chlorpropamide (β = −0.897) no diabetic medicine prescribed (β = −0.865) manner in which the patient was discharged (β = 0.824).  Figure 2. The 5 most important factors for the \u0026lt;30 classifier. Red means negative values while green means positive.\n\u0026gt;30 class (readmitted after 30 days) The most important factors were:\n number of emergency (β = 4.285) outpatient (β = 2.836) inpatient (β = 2.558) visits the prescription of miglitol (β = 1.606) and the number of diagnoses(β = 1.285).  Figure 3. The 5 most important factors for the \u0026gt;30 classifier. Red means negative values while green means positive.\nNo Readmission class The most important factors were\n the number of emergency (β = −6.179) inpatient (β = −5.287) outpatient visits (β = −3.110) in the preceding year the number of diagnoses (β = −1.820) whether a patient was prescribed miglitol (β = −0.792).  Figure 4. The 5 most important factors for the no readmission classifier. Red means negative values while green means positive.\nIt makes sense that the values for no record of readmission and readmission after 30 days have values on opposite ends of the scales. The features themselves make sense too, as you’re more likely to need a second visit if you’ve already been visiting the hospital enough in the previous year and have several diagnoses.\nPredictive Models Neural Networks with PyTorch As with the logistic regression model, some preprocessing was done to the data.\n Normalized using MinMaxNormalization split into a training and test set  with the first 60,000 data points in the training set the rest in the test set.   one-hot encoded as before.  Neural networks were implemented using Pytorch. We tried two different network structures. Both networks had 73 input nodes and 3 output nodes.\n One network had a hidden layer with 200 nodes One network had 2 hidden layers with 200 nodes each. The batch size was 256 because we wanted a large batch for stable training. The learning rate was set at 0.0001 so that we could track the learning process. With too high of a learning rate, the model seemed likely to overfit.  Both models achieved exactly the same accuracy of 0.601 which was surprising. It seems like the second hidden layer may have been redundant, however when we look at plots of the loss and accuracy, we see that the two layer network converges faster.\nFigure 5. Performance of both networks. The loss over 20 epochs of training.\nFigure 6 Performance of both networks. The accuracy on the held out test set of data.\nDecision Trees (Scikit-learn) To run decision trees on the data, the categorical features still needed\n Ran MinMaxNormalization to be one-hot encoded Separated the data into a training and test split with 60,000 data points to stay consistent with the other models, though the data wasn’t shuffled for this model.  We used the scikit-learn implementation of a Decision Tree Classifier.\n Splits : decided based on information gain minParent: left at the default value of 2. maximum depth : We tested a few different values to set for the maximum depth of the tree and found that a max depth of 2 or 3 yielded the highest accuracy of 0.701.  Accuracy 0.701\nRandom Forest (Scikit-learn) Ensemble of decision tree\nSince we know that decision trees are prone to overfitting, we used scikit learn’s RandomForestClassifier to build an ensemble of decision trees. Using what we learned from our decision tree, we built the forest using\n trees of max depth 3 minParent 2 Splits were calculated using information gain  Findings We found that whether we used 100 or 1000 trees, the accuracy of 0.730 did not change. However, the accuracy drastically changes whether each class is given the same weight or is given a weight inversely proportional to its frequency. If the weights are not equal, accuracy tanks to 0.384 which makes sense because the number of no readmissions is almost twice that of the next frequent class, readmissions after 30 days.\nFigure 7. The 5 most important factors for splits made in trees of the random forest.\nConclusion We tried a variety of machine learning techniques on this 3-class classification problem. First we made feature selections and tried to use PCA to reduce the number of features. Then we trained various models and measured their accuracy.\nComparison between models for performance on Diabete\u0026rsquo;s readmission rates:\n   Model Performance     Neural Network 0.601   logistic regression 0.609   decision tree 0.701   random forest 0.730    As we learned in class, ensembles can be very powerful because they’re less prone to overfitting and can generalize better. Our results support this. Also, the model\u0026rsquo;s successful performance is dependent on the feature inpatient, which is the number of inpatient visits of the patient in the year preceding the encounter. This feature has been indicated important in both logistic regression and decision trees.\n","date":1576448312,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576448312,"objectID":"3ac56306ae027a31ce64eb82e3a1e610","permalink":"https://zhouxiaojue.github.io/project/diabetesprediction/","publishdate":"2019-12-15T14:18:32-08:00","relpermalink":"/project/diabetesprediction/","section":"project","summary":"Neural Networks, Random Forests, and Logistic Regression.","tags":["ML"],"title":"Predicting Diabetes Readmission Rates with Machine Learning Tools","type":"project"},{"authors":[],"categories":null,"content":"","date":1572274800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572274800,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://zhouxiaojue.github.io/talk/functional-connectivity-during-action-recognition-modulated-by-top-down-goals/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/functional-connectivity-during-action-recognition-modulated-by-top-down-goals/","section":"event","summary":"Functional connection between pSTS and IFG modulated by attention.","tags":[],"title":"Functional Connectivity During Action Recognition Modulated By Top-down Goals","type":"event"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://zhouxiaojue.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Kenwood M","Oler J","Fox A","Tromp D","Zhou X","Riedel M","Kalin N"],"categories":null,"content":"","date":1504224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504224000,"objectID":"c0488816129a4cf702c3bf74e58fde55","permalink":"https://zhouxiaojue.github.io/publication/kalin2017_2/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/kalin2017_2/","section":"publication","summary":"","tags":null,"title":"Consequences of Altering Prefrontal-Temporal Lobe Connectivity in Young Nonhuman Primates","type":"publication"},{"authors":["Xiaojue Zhou"],"categories":["statistic modeling"],"content":"The problem The sampling problem: if we sample faithfully to the real subpopulation ratio within a population (the true random sampling strategy), then we might get unstable estimates. However, if we oversample in one subpopulation, then we have to correct for the oversampling. For example, autism twins are very rare. If we want to accurately measure their psychologycal assessments, we want to upsample by intentionally taking more measurements in autism twin pairs than we would if we stay true to the ratio of autism twin pairs to normal twin pairs.\nHere, RDoC Study (2010-2012) Subsampling of Twin Pairs With Unequal Probability was a health survey on functional and structural neuroimaging and psychological assessments. They used a power strategy and took more samples in autism twin pairs.\nMy problem here is to pick a statistical strategy to estimate the true weights so the researchers can apply on their measurements to achieve both efficient and unbiased analysis.\nApproach Models to estimate weights Current study looks at different ways to calculate sample weights and compare their performances on the current dataset. Here, linear regression, polynomial regression, gamma linear regression, and gamma polynomial regression were used to estimate weights.\nBootstrapping to evaluate model performance 10000 times bootstrapping were performed to evaluate how different models performed in estimating weights.\nMeasurements of model performance   Efficiency : Ratio of standard deviation of bootstrapped original weights comparing to bootstrapped weights based on various methods described above. This is telling us how our newly estimated weights varied comparing to original weights.\n  Bias : Difference between average bootstrapped estimates. Here, it is the difference between original weights to bootstrapped weights based on methods described above. This is telling us how different our newly estimated weights comparing to original weights.\n  Results 1. Were the parameters biased?\nThe table below indicated that the parameter estimates were close to it\u0026rsquo;s original estimates. Also, across all the models, bias of different estimates (age, race, etc.,) were around zero. 2. Were the estimated weights efficient?\nHere, yg and xyg model, which was gamma modeling of unsmoothed and smoothed sampling weights had the highest efficiency in estimating weights.\nConclusion While all the models used above can estimate accuracte weights, Gamma and linear models using either un-smoothed or smoothed estimates have the highest efficiency in estimating weights.\nResource You can find the R code to do this analysis in my github respoitory.\n","date":1462313653,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1462313653,"objectID":"a6a869e80cfd8edbfdb55b970b487756","permalink":"https://zhouxiaojue.github.io/project/surveyweight/","publishdate":"2016-05-03T14:14:13-08:00","relpermalink":"/project/surveyweight/","section":"project","summary":"Comparing different approaches to correct oversample datasets.","tags":["Statistics"],"title":"Statistical Analysis of Weighted Survey Data in R","type":"project"},{"authors":["Xiaojue Zhou"],"categories":["experimental design"],"content":"The Problem Past studies already demonstrate strong emotional content of words improves people’s immediate recall memory and consistent colors further enhance memory(Donald et al., 2004). It is interesting to see if same conclusion can be draw on metamemory and whether the color still interacts with emotion. If so, we can say this effect is immediate and on-line.\nBesides looking at people’s memory ability, we can also look at how people recognize this cognitive ability. Metacognition is “thinking of thinking”. Metamemory is the introspective cognition about one’s own memory ability. It is a self-judgment. While people’s natural memory capacity would restrain number of words actually remembered, words’ attributes may have larger effect on decision of one’s judgment of memory ability.\nOne hypothesis of current study is participants will remember more words when words are more familiar or easier to imagine. However, participants may not consider themselves remember (metamemory) more imaginable words but they will for more familiar words, for the reason that imageability is not very easy to identify at first impression. The current paper studies how four attributes—imageability, familiarity, emotional valence and associated colors—affect people’s ability to remember words.\nFactorial design is an efficient way to design experiment to quickly investigate individual variable effects, as well as the ability to study interaction effects between variables. Here I will used factorial design with repeated measure to understand the following questions.\nHypothesis:\n  How word\u0026rsquo;s properties influence human memory ability?\n  How does individual word\u0026rsquo;s properties influence the differences in metacognition and recall?\n  Example stimuli of emotional valence and color variable. Each participant received a list of 20 words and ask to remember them.  Experimental Design Independent Variables Here I used 4X3 repeated measure design to study the following effects both individually and also their interactions.\n Emotional Valence Imageability Familiarity Colors  Design Specific design here is a full factorial design. Words’ order in each list was completely randomized. Each condition was replicated three times (three blocks) and each block contained completely randomized orders of 16 trials.\nMeasurements of memory   meta-memory : number of words they think they will remember. This measured subjects\u0026rsquo;s metacognition of self memory.\n  actual recall : number of words actually written down correctly. This is used to compare with meta-memory.\n  What I found While individual ANOVA analysis of response variable recall, or meta-cognition has not shown any significant effect dependent on words' properties. I further only looked at words overlap between words subjects they thought they would remember, and also they actually recalled later.\nHere I found out three $\\rho \u0026lt; 0.01$ interaction effects on the items subjects both thought they would remember, and also they actually recalled:\n Imageability and familarity Imageability and colors Emotional valence and familarity  Here it indicated that more imagenable and familiar words lead to better memory and also made deeper impression both consciously (through meta-cognition) and also subconsciously (recall).\nParticipants characteristics by Condition I additionally analyze how the participants use to remember words.\n Participants used at least one strategy (9.33) remember more than participants used no strategy at all (8.125). Most participants used strategies such as association, twist letter, phonetic clues to remember words.  Conclusion English words with following properties made more impression:\n Familiar words Negative words Emotional words  Also, words in cooler colors allowed subjects to imagine those words more easily, therefore possibly increasing their memory on those words. Additionally, using a strategy was important to recall english words.\nResource My code to analyze the experiment data can be found here (R Markdown file) and also on my github repository. If you want to replicate this experiment yourself, here is the materials (Wordlist.pdf) I used to conduct this experiment.\n","date":1449526735,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1449526735,"objectID":"c085e70ec82beac36a74705ed122030c","permalink":"https://zhouxiaojue.github.io/project/wordproperties/","publishdate":"2015-12-07T14:18:55-08:00","relpermalink":"/project/wordproperties/","section":"project","summary":"English Words’ Properties on Metacognition of Self-Memory","tags":["Statistics","Behavior"],"title":"What kind of words can influence our memory?","type":"project"},{"authors":["Xiaojue Zhou"],"categories":["Survey Design"],"content":"Motivation Most of the procrastination questionnaire is old, and subtypes of procrastination has been definied but not applied. While most people studied anxiety behind procrastination and rather used vague questions to ask individual subjects on their patterns of daily activity. I was interested in building a questionnaire specifically targeting college students.\nQuestionnaire Construction What the textbook says From Crocker \u0026amp; Algina\u0026rsquo;s textbook : Introduction to Classical and Modern Test Theory, they suggested the following steps when constructing a test.\n Identify the primary purpose of the test score use Identify behaviors to represent the construct  content analysis review of research critical incident direct observation expert judgement instruction objectives   Domain sampling Item construction Item review  How I wrote the questionnaire First of all, I want to know what it means exactly by procrastination.\n1. Procrastination definition\nProcrastination is the unplanned delaying tasks and procrastinators often feel guilty about their procrastination.\n2. Literature Research\nThen, I wanted to know if any researchers has systematically studied procrastination. So I searched studies on academic procrastination and summarized their findings on procrastination.\nSpecifically, procrastination can be divided into two categories.\n decisional procrastination behavioral procrastination.  3. Brain Storm\nAfter studying about procrastination study, then I visualized what a procrastinator (like myself) would do in each category.\nTypical behaviors of procrastinators are:\n missing deadlines making decisions until last minutes spend time on meaningless task before finishing task  Additionally, I included questions to ask about how individuals recognize their procrastination by asking question in these two additional categories.\n how they feel about procrastination the reasons for procrastinations  My questionnaire The current questionnaire is a self-evaluating scale focused on behavioral and decisional procrastinations in daily life and academic, reasons of procrastinations and feelings about procrastinations.\n Initially I had 50 items, then I analyzed the collected responses and end up with 25 items. 5-point likert scale  Population and sample I collected responses from 25 classmates in my psychometric class, which are all graduate students in academics so it fits my desired academic population.\nMeasuring my questionnaire I used the following measurements to understand how effective my questionnaire is at evaluating people\u0026rsquo;s internal states.\n Cohen\u0026rsquo;s kappa : Cohen\u0026rsquo;s kappa measures the agreement between two raters who each classify N items into mutually exclusive categories. inter-rater agreement : confidence of whether the cluster I assign it to other people also assign it to.  Potential Impact Procrastination scores were often related to lower self-regulations, lower self-efficacy, and higher neuroctism of personality trait. While most people would recognize procrastination as part of their personality, I hope this questionnaire would be their first step to identify specific behavior pattern and their general tendency to procrastination.\nImprovements Unfortunately, I lost the original collected data therefore cannot recover the measured statistics on individual items. This questionnaire was a psychometric class project and therefore hasn\u0026rsquo;t been widely studied in a bigger subject pool. If I have an opportunity, I would specifically collect responses from undergraduate students and see how different the response is comparing to graduate students'. Also, this questionnaire was designed in 2014 and people probably procrastinate with different things with advances in technology in 2021 (2021 still sounds like future to me).\nResources If you are intersted in using my questionnaire, you can find the printable pdf here (Procrastination Survey).\n","date":1417990712,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1417990712,"objectID":"596babcaad297daa12118f458a44b3cf","permalink":"https://zhouxiaojue.github.io/project/procrastinatequestionnaire/","publishdate":"2014-12-07T14:18:32-08:00","relpermalink":"/project/procrastinatequestionnaire/","section":"project","summary":"How to design a questionnaire and also analyze response?","tags":["Behavior"],"title":"Procrastination Questionnaire Construction","type":"project"},{"authors":["Xiaojue Zhou"],"categories":[],"content":"What we want The problem In English, individual flowers are usually named with specific name of that flower (e.g., rose, tulip). However, in Chinese flowers are usually named by both the basic level name (e.g., rose, tulip) followed by subordinate level name (花, flower). For example, chamomile is named 菊花 or chamomile flower. Therefore, it\u0026rsquo;s possible that Chinese native speakers categorize daily objects differently because how Chinese has built-in category information in the language.\nHere, we are interested in finding the priming effects of the language. First of all, we need a standardized bank of based on Chinese speakers in order to find the most representable objects inside each basic levle category (e.g., a typical dog species within dog, typical flower within flower)\nWhat We Had A bank of stimuli First, we collected a bank of stimuli using daily objects. In the table below, each row is an picture representing a daily object. We want to know on average, if each item is named correctly and also consistenty among all the subjects.\nDesign experiment to observe verbal response An example stimuli In the experiment, we asked each subject to name a total of 400 individual pictures of objects and collected over 30 subjects' verbal response to each picture, as well as how fast they name the object.\nMeasurements of individual items For each item (picture), we calculated the following statistics:\n Entropy Average naming accuracy Total number of different labels Average response time  What We Found While this is still an ongoing project, we have established the bank of 285 individual pictures of daily animals and daily objects, each comes with the following information:\n Standardized Chinese name Corresponding English names Item\u0026rsquo;s basic semantic level Item\u0026rsquo;s surordinate level Average Response time Entropy  Future If you are interested in collaboration, please contact halleycl at gmail dot com. We would love to have people use this stimuli bank!\n","date":1391811483,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1391811483,"objectID":"2916ef4397a8913c5560ec8a7adc4f20","permalink":"https://zhouxiaojue.github.io/project/chineseword/","publishdate":"2014-02-07T14:18:03-08:00","relpermalink":"/project/chineseword/","section":"project","summary":"A Behavioral Study on Priming effects of Chinese words on Semantic Understanding of Daily Objects","tags":["Behavior"],"title":"How speaking a different language influneces our semantic understanding","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://zhouxiaojue.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]