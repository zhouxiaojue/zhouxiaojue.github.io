<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Xiaojue Zhou</title>
    <link>https://zhouxiaojue.github.io/project/</link>
      <atom:link href="https://zhouxiaojue.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 07 Feb 2021 14:18:55 -0800</lastBuildDate>
    <image>
      <url>https://zhouxiaojue.github.io/images/icon_huceba9e9d4a8c609672b14db0e634331f_215354_512x512_fill_lanczos_center_2.png</url>
      <title>Projects</title>
      <link>https://zhouxiaojue.github.io/project/</link>
    </image>
    
    <item>
      <title>WordProperties</title>
      <link>https://zhouxiaojue.github.io/project/wordproperties/</link>
      <pubDate>Sun, 07 Feb 2021 14:18:55 -0800</pubDate>
      <guid>https://zhouxiaojue.github.io/project/wordproperties/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ProcrastinateQuestionnaire</title>
      <link>https://zhouxiaojue.github.io/project/procrastinatequestionnaire/</link>
      <pubDate>Sun, 07 Feb 2021 14:18:32 -0800</pubDate>
      <guid>https://zhouxiaojue.github.io/project/procrastinatequestionnaire/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Statistical Analysis of Weighted Survey Data in R</title>
      <link>https://zhouxiaojue.github.io/project/surveyweight/</link>
      <pubDate>Tue, 03 May 2016 14:14:13 -0800</pubDate>
      <guid>https://zhouxiaojue.github.io/project/surveyweight/</guid>
      <description>&lt;h2 id=&#34;the-problem&#34;&gt;&lt;strong&gt;The problem&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The sampling problem: if we sample faithfully to the real subpopulation ratio within a population (the true random sampling strategy), then we might get unstable estimates. However, if we oversample in one subpopulation, then we have to correct for the oversampling. For example, autism twins are very rare. If we want to accurately measure their psychologycal assessments, we want to upsample by intentionally taking more measurements in autism twin pairs than we would if we stay true to the ratio of autism twin pairs to normal twin pairs.&lt;/p&gt;
&lt;p&gt;Here, RDoC Study (2010-2012) Subsampling of Twin Pairs With Unequal Probability was a health survey on functional and structural neuroimaging and psychological assessments. They used a power strategy and took more samples in autism twin pairs.&lt;/p&gt;
&lt;p&gt;My problem here is to pick a statistical strategy to estimate the true weights so the researchers can apply on their measurements to achieve both efficient and unbiased analysis.&lt;/p&gt;
&lt;h2 id=&#34;approach&#34;&gt;&lt;strong&gt;Approach&lt;/strong&gt;&lt;/h2&gt;
&lt;h4 id=&#34;models-to-estimate-weights&#34;&gt;&lt;strong&gt;Models to estimate weights&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Current study looks at different ways to calculate sample weights and compare their performances on the current dataset. Here, linear regression, polynomial regression, gamma linear regression, and gamma polynomial regression were used to estimate weights.&lt;/p&gt;
&lt;h4 id=&#34;bootstrapping-to-evaluate-model-performance&#34;&gt;&lt;strong&gt;Bootstrapping to evaluate model performance&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;10000 times bootstrapping were performed to evaluate how different models performed in estimating weights.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;SurveyWeights.png&#34; alt=&#34;Survey weights estimate process&#34; title=&#34;Analysis flow chart&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;measurements-of-model-performance&#34;&gt;&lt;strong&gt;Measurements of model performance&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Efficiency&lt;/strong&gt; : Ratio of standard deviation of bootstrapped original weights comparing to
bootstrapped weights based on various methods described above. This is telling us how our newly estimated weights varied comparing to original weights.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Bias&lt;/strong&gt; : Difference between average bootstrapped estimates. Here, it is the difference between original weights to bootstrapped weights based on methods described above. This is telling us how different our newly estimated weights comparing to original weights.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;results&#34;&gt;&lt;strong&gt;Results&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1. Were the parameters biased?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The table below indicated that the parameter estimates were close to it&amp;rsquo;s original estimates.
&lt;img src=&#34;TableWeights.png&#34; alt=&#34;Weighted estimates comparison&#34; title=&#34;Weighted estimates comparison&#34;&gt;&lt;/p&gt;
&lt;p&gt;Also, across all the models, bias of different estimates (age, race, etc.,) were around zero.
&lt;img src=&#34;BiasLine.png&#34; alt=&#34;Weighted estimates line&#34; title=&#34;Weighted estimates comparison&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. Were the estimated weights efficient?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Here,  yg and xyg model, which was gamma modeling of unsmoothed and smoothed sampling weights had the highest efficiency in estimating weights.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;Efficiency.png&#34; alt=&#34;Efficiency of bootstrap estimates&#34; title=&#34;Weighted estimates comparison&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;While all the models used above can estimate accuracte weights, Gamma and linear models using either un-smoothed or smoothed estimates have the highest efficiency in estimating weights.&lt;/p&gt;
&lt;h2 id=&#34;resource&#34;&gt;&lt;strong&gt;Resource&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;You can find the R code to do this analysis in my github respoitory.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How speaking a different language influneces our semantic understanding</title>
      <link>https://zhouxiaojue.github.io/project/chineseword/</link>
      <pubDate>Fri, 07 Feb 2014 14:18:03 -0800</pubDate>
      <guid>https://zhouxiaojue.github.io/project/chineseword/</guid>
      <description>&lt;h2 id=&#34;what-we-want&#34;&gt;&lt;strong&gt;What we want&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&#34;the-problem&#34;&gt;&lt;strong&gt;The problem&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;FlowerAll.jpg&#34; alt=&#34;Flowers&#34; title=&#34;All Flowers belong to flower category&#34;&gt;&lt;/p&gt;
&lt;p&gt;In English, individual flowers are usually named with specific name of that flower (e.g., rose, tulip). However, in Chinese flowers are usually named by both the basic level name (e.g., rose, tulip) followed by subordinate level name (花, flower). For example, chamomile is named 菊花 or chamomile flower. Therefore, it&amp;rsquo;s possible that Chinese native speakers categorize daily objects differently because how Chinese has built-in category information in the language.&lt;/p&gt;
&lt;p&gt;Here, we are interested in finding the priming effects of the language. First of all, we need a standardized bank of based on Chinese speakers in order to find the most representable objects inside each basic levle category (e.g., a typical dog species within dog, typical flower within flower)&lt;/p&gt;
&lt;h2 id=&#34;what-we-had&#34;&gt;&lt;strong&gt;What We Had&lt;/strong&gt;&lt;/h2&gt;
&lt;h4 id=&#34;a-bank-of-stimuli&#34;&gt;A bank of stimuli&lt;/h4&gt;
&lt;p&gt;First, we collected a bank of stimuli using daily objects. In the table below, each row is an picture representing a daily object. We want to know on average, if each item is named correctly and also consistenty among all the subjects.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;DesiredOutcome.png&#34; alt=&#34;Desired bank of stimuli&#34; title=&#34;Desired bank of stimuli&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;design-experiment-to-observe-verbal-response&#34;&gt;Design experiment to observe verbal response&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;goldRetriever.jpeg&#34; alt=&#34;Stimuli&#34; title=&#34;Example stimuli&#34;&gt;&lt;/p&gt;
&lt;div align = &#34;center&#34;&gt;An example stimuli&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;Response.png&#34; alt=&#34;Response&#34; title=&#34;Response of stimuli&#34;&gt;&lt;/p&gt;
&lt;p&gt;In the experiment, we asked each subject to name a total of 400 individual pictures of objects and collected over 30 subjects&#39; verbal response to each picture, as well as how fast they name the object.&lt;/p&gt;
&lt;h4 id=&#34;measurements-of-individual-items&#34;&gt;Measurements of individual items&lt;/h4&gt;
&lt;p&gt;For each item (picture), we calculated the following statistics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Entropy&lt;/li&gt;
&lt;li&gt;Average naming accuracy&lt;/li&gt;
&lt;li&gt;Total number of different labels&lt;/li&gt;
&lt;li&gt;Average response time&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-we-found&#34;&gt;&lt;strong&gt;What We Found&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;While this is still an ongoing project, we have established the bank of 285 individual pictures of daily animals and daily objects, each comes with the following information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Standardized Chinese name&lt;/li&gt;
&lt;li&gt;Corresponding English names&lt;/li&gt;
&lt;li&gt;Item&amp;rsquo;s basic semantic level&lt;/li&gt;
&lt;li&gt;Item&amp;rsquo;s surordinate level&lt;/li&gt;
&lt;li&gt;Average Response time&lt;/li&gt;
&lt;li&gt;Entropy&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;future&#34;&gt;&lt;strong&gt;Future&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;If you are interested in collaboration, please contact halleycl at gmail dot com. We would love to have people use this stimuli bank!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
