<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Xiaojue Zhou</title>
    <link>https://zhouxiaojue.github.io/</link>
      <atom:link href="https://zhouxiaojue.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Xiaojue Zhou</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 01 Dec 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://zhouxiaojue.github.io/images/icon_huceba9e9d4a8c609672b14db0e634331f_215354_512x512_fill_lanczos_center_2.png</url>
      <title>Xiaojue Zhou</title>
      <link>https://zhouxiaojue.github.io/</link>
    </image>
    
    <item>
      <title>Where Are Our Action Predictions? Action Understanding as a Predictive Process: Integrative Model and Neuroimage Evidence</title>
      <link>https://zhouxiaojue.github.io/publication/litreview_2020_2/</link>
      <pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://zhouxiaojue.github.io/publication/litreview_2020_2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Where for what: A meta-analysis for the category-specific activations for living/nonliving concepts in the past two decades</title>
      <link>https://zhouxiaojue.github.io/publication/metaanalysis2020_2/</link>
      <pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://zhouxiaojue.github.io/publication/metaanalysis2020_2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Neuroimage format and orientation information in nifti</title>
      <link>https://zhouxiaojue.github.io/post/imageorientation/</link>
      <pubDate>Fri, 11 Dec 2020 11:39:25 -0800</pubDate>
      <guid>https://zhouxiaojue.github.io/post/imageorientation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Sensory and Social Cognitive Networks Connectivity Depends on Attentive States.</title>
      <link>https://zhouxiaojue.github.io/publication/ifg2021/</link>
      <pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://zhouxiaojue.github.io/publication/ifg2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Top-down attention guidance shapes action encoding in the pSTS</title>
      <link>https://zhouxiaojue.github.io/publication/mvpa2020_2/</link>
      <pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://zhouxiaojue.github.io/publication/mvpa2020_2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>How to do surface functional connectivity analysis?</title>
      <link>https://zhouxiaojue.github.io/post/bvsurface/</link>
      <pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://zhouxiaojue.github.io/post/bvsurface/</guid>
      <description>&lt;h3 id=&#34;understanding-surface&#34;&gt;Understanding Surface&lt;/h3&gt;
&lt;h3 id=&#34;preprocessing-in-brain-voyager&#34;&gt;Preprocessing in Brain Voyager&lt;/h3&gt;
&lt;h3 id=&#34;surface-reconstruction-in-freesurfer&#34;&gt;Surface reconstruction in freesurfer&lt;/h3&gt;
&lt;h3 id=&#34;surface-group-normalization-cba-alignment-in-bv&#34;&gt;Surface group normalization (CBA alignment in BV)&lt;/h3&gt;
&lt;h3 id=&#34;move-functional-data-to-native-surface-bv&#34;&gt;Move functional data to native surface (BV)&lt;/h3&gt;
&lt;h3 id=&#34;move-functional-data-to-reference-surface-bv&#34;&gt;Move functional data to reference surface (BV)&lt;/h3&gt;
&lt;h3 id=&#34;move-volumetric-roi-voi-to-surface-roi-poi-bv&#34;&gt;Move volumetric ROI (VOI) to surface ROI (POI) (BV)&lt;/h3&gt;
&lt;h3 id=&#34;calculate-functional-connectivity-in-matlab&#34;&gt;Calculate functional connectivity in MATLAB&lt;/h3&gt;
&lt;h3 id=&#34;export-functional-connectivity-map-to-surface-statistical-maps-for-visualization-bv&#34;&gt;Export functional connectivity map to surface statistical maps for visualization (BV)&lt;/h3&gt;
&lt;h3 id=&#34;non-parametric-testing-for-thresholding-whole-brain-connectivity-analysis&#34;&gt;Non-parametric testing for thresholding whole brain connectivity analysis&lt;/h3&gt;
&lt;p&gt;More Coming&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Predicting Diabetes Readmission Rates with Machine Learning Tools</title>
      <link>https://zhouxiaojue.github.io/project/diabetesprediction/</link>
      <pubDate>Sun, 15 Dec 2019 14:18:32 -0800</pubDate>
      <guid>https://zhouxiaojue.github.io/project/diabetesprediction/</guid>
      <description>&lt;h1 id=&#34;purpose&#34;&gt;Purpose&lt;/h1&gt;
&lt;p&gt;Our group chose to work with the Diabetes 130-US Hospitals dataset for this project. This dataset contains 10 years of patient diabetes records collected from 130 hospitals in the US.
The dataset contains&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;101,766 records&lt;/li&gt;
&lt;li&gt;49 features&lt;/li&gt;
&lt;li&gt;3 class labels.
A description of the features and the amount of missing data in each category can be found at &lt;a href=&#34;https://www.hindawi.com/journals/bmri/2014/781670/tab1/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.hindawi.com/journals/bmri/2014/781670/tab1/&lt;/a&gt; so we will not spend time explaining them here.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;what-we-are-predicting&#34;&gt;What we are predicting&lt;/h1&gt;
&lt;p&gt;The 3 class labels our models will predict are
We are trying to understand the diabete&amp;rsquo;s readmission rates in relationship to other variables. Specifically, re-admission rates referred to whether or not a patient is readmitted to the hospital after the visit recorded in the database.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;&amp;lt;30&amp;rdquo; : whether the patient was readmitted in less than 30 days&lt;/li&gt;
&lt;li&gt;&amp;ldquo;&amp;gt;30&amp;rdquo; : whether the patient was readmitted in more than 30 days&lt;/li&gt;
&lt;li&gt;&amp;ldquo;NO&amp;rdquo; : no record of readmission exists&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;cleaning-the-data-and-feature-selection&#34;&gt;Cleaning the Data and Feature Selection&lt;/h1&gt;
&lt;h3 id=&#34;missing-data&#34;&gt;Missing Data&lt;/h3&gt;
&lt;p&gt;First we looked at those features with high amounts of missing data:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;weight (97% missing, will fit model with and without)&lt;/li&gt;
&lt;li&gt;payer code (not relevant for diabetes itself but maybe interesting to look in the future)&lt;/li&gt;
&lt;li&gt;medical specialty (53% missing)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We found out 97% of the weight data was missing so then we decided there was no worth in trying to include it in our analyses. We also threw out the payer code feature because the type of health insurance a patient has should have very little bearing on a patient’s care and whether they will be readmitted. We went back and forth on whether to keep medical specialty - which is a feature describing the speciality of the attending doctor. 53% of the data was missing in this category. After inspecting the values this feature could take on (84 distinct values in total) we decided it was out of scope for the project to try and reconstruct the missing values and also decided to exclude this feature from our final analyses.&lt;/p&gt;
&lt;p&gt;We also delete these empty features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;examide: No patients were prescribed this drug&lt;/li&gt;
&lt;li&gt;citoglipton: No patients were prescribed this drug&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Also, we deleted these features with less than 2 inputs&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;glimepiride&lt;/li&gt;
&lt;li&gt;pioglitazone&lt;/li&gt;
&lt;li&gt;acetohexamide&lt;/li&gt;
&lt;li&gt;metformin.pioglitazone&lt;/li&gt;
&lt;li&gt;metformin.rosiglitazone&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;transform-data&#34;&gt;Transform Data&lt;/h3&gt;
&lt;p&gt;Comorbidity:&lt;br&gt;
The ICD-9 codes that were used as values for diag1, diag2, and diag3 (diagnoses) were remapped to 9 categorical values that indicated the type of disease:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Circulatory&lt;/li&gt;
&lt;li&gt;Respiratory&lt;/li&gt;
&lt;li&gt;Digestive&lt;/li&gt;
&lt;li&gt;Diabetes&lt;/li&gt;
&lt;li&gt;Injury&lt;/li&gt;
&lt;li&gt;Musculoskeletal&lt;/li&gt;
&lt;li&gt;Genitourinary&lt;/li&gt;
&lt;li&gt;Neoplasms&lt;/li&gt;
&lt;li&gt;Other&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Multiple visits:
Finally, we noticed that some patient identifying numbers were repeated more than once, indicating multiple visits from the same person. In order to be able to assume independence of our data points, we only kept the first visit (as identified using encounter ids) for each patient and threw out the rest.&lt;/p&gt;
&lt;h3 id=&#34;cleaned-dataset&#34;&gt;Cleaned Dataset&lt;/h3&gt;
&lt;p&gt;Out final cleaned dataset:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;number of data points: 71,518 rows&lt;/li&gt;
&lt;li&gt;number of features: 38 columns&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;exploratory-data-analysis&#34;&gt;Exploratory Data Analysis&lt;/h1&gt;
&lt;h3 id=&#34;pca&#34;&gt;PCA&lt;/h3&gt;
&lt;p&gt;In an attempt to reduce the number of features further, we performed a principal components analysis (PCA) but this did not prove too informative. The first principal component only accounted for 5.5% of the data. Therefore we decided to keep the rest of our features. Figure 1 shows how much each feature explains the data set. The features making the most contributions are indicator variables that say whether or not diabetes medication was prescribed to the patient and whether or not there was a change in dosage for prescribed medication. These features together accounted for 10% of the data. Whether diabetes medication was prescribed and whether there was a change are highly correlated. We suspect this may be because if a patient’s condition is worsening, then a new medication may be prescribed or a higher dosage given and thus there will be a change in dosage. Alternatively, if a patient’s condition is improving, their dosage may be decreased and this is still a change. If someone is not prescribed medicine at all, then there will be no change to administer.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;PCA_Variable.jpeg&#34; alt=&#34;PCA Plots&#34;&gt;&lt;/p&gt;
&lt;p&gt;Figure 1. Principal components of the data and how much each accounted for the data.&lt;/p&gt;
&lt;h3 id=&#34;logistic-regression&#34;&gt;Logistic Regression&lt;/h3&gt;
&lt;p&gt;We performed some additional preprocessing of the data, namely one-hot encoding the categorical values and shuffling the data. with larger values as more important. After the one-hot encoding, there are 73 features to be used as coefficients in our model.&lt;/p&gt;
&lt;p&gt;The data was also split into a training set and a test set, with the first 60,000 data points used for the training set. We trained a multiclass logistic regression model using scikit-learn. Since there are 3 classes, we trained 3 binary classifiers.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;accuracy on the test data was 0.609&lt;/strong&gt;. Additionally, we report the features that had the highest abstract coefficients for each classifier.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&amp;lt; 30 class (readmitted within 30 days)&lt;/strong&gt;
The most important factors were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;number of inpatient (β = 3.899)&lt;/li&gt;
&lt;li&gt;emergency (β = 1.962) visits,&lt;/li&gt;
&lt;li&gt;the prescription of chlorpropamide (β = −0.897)&lt;/li&gt;
&lt;li&gt;no diabetic medicine prescribed (β = −0.865)&lt;/li&gt;
&lt;li&gt;manner in which the patient was discharged (β = 0.824).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;LR_class2.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Figure 2. The 5 most important factors for the &amp;lt;30 classifier. Red means negative values while green means positive.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&amp;gt;30 class (readmitted after 30 days)&lt;/strong&gt;
The most important factors were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;number of emergency (β = 4.285)&lt;/li&gt;
&lt;li&gt;outpatient (β = 2.836)&lt;/li&gt;
&lt;li&gt;inpatient (β = 2.558) visits&lt;/li&gt;
&lt;li&gt;the prescription of miglitol (β = 1.606)&lt;/li&gt;
&lt;li&gt;and the number of diagnoses(β = 1.285).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;LR_class3.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Figure 3. The 5 most important factors for the &amp;gt;30 classifier. Red means negative values while green means positive.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;No Readmission class&lt;/strong&gt;
The most important factors were&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the number of emergency (β = −6.179)&lt;/li&gt;
&lt;li&gt;inpatient (β = −5.287)&lt;/li&gt;
&lt;li&gt;outpatient visits (β = −3.110) in the preceding year&lt;/li&gt;
&lt;li&gt;the number of diagnoses (β = −1.820)&lt;/li&gt;
&lt;li&gt;whether a patient was prescribed miglitol (β = −0.792).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;LR_class2.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Figure 4. The 5 most important factors for the no readmission classifier. Red means negative values while green means positive.&lt;/p&gt;
&lt;p&gt;It makes sense that the values for no record of readmission and readmission after 30 days have values on opposite ends of the scales. The features themselves make sense too, as you’re more likely to need a second visit if you’ve already been visiting the hospital enough in the previous year and have several diagnoses.&lt;/p&gt;
&lt;h1 id=&#34;predictive-models&#34;&gt;Predictive Models&lt;/h1&gt;
&lt;h3 id=&#34;neural-networks-with-pytorch&#34;&gt;Neural Networks with PyTorch&lt;/h3&gt;
&lt;p&gt;As with the logistic regression model, some preprocessing was done to the data.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Normalized using MinMaxNormalization&lt;/li&gt;
&lt;li&gt;split into a training and test set
&lt;ul&gt;
&lt;li&gt;with the first 60,000 data points in the training set&lt;/li&gt;
&lt;li&gt;the rest in the test set.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;one-hot encoded as before.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Neural networks were implemented using Pytorch. We tried two different network structures. Both networks had 73 input nodes and 3 output nodes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;One network had a hidden layer with 200 nodes&lt;/li&gt;
&lt;li&gt;One network had 2 hidden layers with 200 nodes each.&lt;/li&gt;
&lt;li&gt;The batch size was 256 because we wanted a large batch for stable training.&lt;/li&gt;
&lt;li&gt;The learning rate was set at 0.0001 so that we could track the learning process. With too high of a learning rate, the model seemed likely to overfit.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both models achieved exactly the &lt;strong&gt;same accuracy of 0.601&lt;/strong&gt; which was surprising. It seems like the second hidden layer may
have been redundant, however when we look at plots of the loss and accuracy, we see that the two layer network converges
faster.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;loss.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Figure 5. Performance of both networks. The loss over 20 epochs of training.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;acc.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Figure 6 Performance of both networks. The accuracy on the held out test set of data.&lt;/p&gt;
&lt;h3 id=&#34;decision-trees-scikit-learn&#34;&gt;Decision Trees (Scikit-learn)&lt;/h3&gt;
&lt;p&gt;To run decision trees on the data, the categorical features still needed&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ran MinMaxNormalization to be one-hot encoded&lt;/li&gt;
&lt;li&gt;Separated the data into a training and test split with 60,000 data points to stay consistent with the other models, though the data wasn’t shuffled for this model.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We used the scikit-learn implementation of a Decision Tree Classifier.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Splits : decided based on information gain&lt;/li&gt;
&lt;li&gt;minParent: left at the default value of 2.&lt;/li&gt;
&lt;li&gt;maximum depth : We tested a few different values to set for the maximum depth of the tree and found that a max depth of 2 or 3 yielded the highest accuracy of 0.701.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Accuracy&lt;/strong&gt;
&lt;strong&gt;0.701&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;random-forest-scikit-learn&#34;&gt;Random Forest (Scikit-learn)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Ensemble of decision tree&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Since we know that decision trees are prone to overfitting, we used scikit learn’s RandomForestClassifier to build an ensemble of decision trees. Using what we learned from our decision tree, we built the forest using&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;trees of max depth 3&lt;/li&gt;
&lt;li&gt;minParent 2&lt;/li&gt;
&lt;li&gt;Splits were calculated using information gain&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Findings&lt;/strong&gt;
We found that whether we used 100 or 1000 trees, the accuracy of 0.730 did not change. However, the accuracy drastically changes whether each class is given the same weight or is given a weight inversely proportional to its frequency. If the weights are not equal, accuracy tanks to 0.384 which makes sense because the number of no readmissions is almost twice that of the next frequent class, readmissions after 30 days.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;feat_imp.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Figure 7. The 5 most important factors for splits made in trees of the random forest.&lt;/p&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;We tried a variety of machine learning techniques on this 3-class classification problem. First we made feature selections and tried to use PCA to reduce the number of features. Then we trained various models and measured their accuracy.&lt;/p&gt;
&lt;p&gt;Comparison between models for performance on Diabete&amp;rsquo;s readmission rates:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Performance&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Neural Network&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.601&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;logistic regression&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.609&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;decision tree&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.701&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;random forest&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;strong&gt;0.730&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As we learned in class, ensembles can be very powerful because they’re less prone to overfitting and can generalize better. Our results support this.
Also, the model&amp;rsquo;s successful performance is dependent on the feature inpatient, which is the number of inpatient visits of the patient in the year preceding the encounter. This feature has been indicated important in both logistic regression and decision trees.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Functional Connectivity During Action Recognition Modulated By Top-down Goals</title>
      <link>https://zhouxiaojue.github.io/talk/functional-connectivity-during-action-recognition-modulated-by-top-down-goals/</link>
      <pubDate>Mon, 28 Oct 2019 15:00:00 +0000</pubDate>
      <guid>https://zhouxiaojue.github.io/talk/functional-connectivity-during-action-recognition-modulated-by-top-down-goals/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://zhouxiaojue.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://zhouxiaojue.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Consequences of Altering Prefrontal-Temporal Lobe Connectivity in Young Nonhuman Primates</title>
      <link>https://zhouxiaojue.github.io/publication/kalin2017_2/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://zhouxiaojue.github.io/publication/kalin2017_2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Statistical Analysis of Weighted Survey Data in R</title>
      <link>https://zhouxiaojue.github.io/project/surveyweight/</link>
      <pubDate>Tue, 03 May 2016 14:14:13 -0800</pubDate>
      <guid>https://zhouxiaojue.github.io/project/surveyweight/</guid>
      <description>&lt;h2 id=&#34;the-problem&#34;&gt;&lt;strong&gt;The problem&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The sampling problem: if we sample faithfully to the real subpopulation ratio within a population (the true random sampling strategy), then we might get unstable estimates. However, if we oversample in one subpopulation, then we have to correct for the oversampling. For example, autism twins are very rare. If we want to accurately measure their psychologycal assessments, we want to upsample by intentionally taking more measurements in autism twin pairs than we would if we stay true to the ratio of autism twin pairs to normal twin pairs.&lt;/p&gt;
&lt;p&gt;Here, RDoC Study (2010-2012) Subsampling of Twin Pairs With Unequal Probability was a health survey on functional and structural neuroimaging and psychological assessments. They used a power strategy and took more samples in autism twin pairs.&lt;/p&gt;
&lt;p&gt;My problem here is to pick a statistical strategy to estimate the true weights so the researchers can apply on their measurements to achieve both efficient and unbiased analysis.&lt;/p&gt;
&lt;h2 id=&#34;approach&#34;&gt;&lt;strong&gt;Approach&lt;/strong&gt;&lt;/h2&gt;
&lt;h4 id=&#34;models-to-estimate-weights&#34;&gt;&lt;strong&gt;Models to estimate weights&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Current study looks at different ways to calculate sample weights and compare their performances on the current dataset. Here, linear regression, polynomial regression, gamma linear regression, and gamma polynomial regression were used to estimate weights.&lt;/p&gt;
&lt;h4 id=&#34;bootstrapping-to-evaluate-model-performance&#34;&gt;&lt;strong&gt;Bootstrapping to evaluate model performance&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;10000 times bootstrapping were performed to evaluate how different models performed in estimating weights.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;SurveyWeights.png&#34; alt=&#34;Survey weights estimate process&#34; title=&#34;Analysis flow chart&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;measurements-of-model-performance&#34;&gt;&lt;strong&gt;Measurements of model performance&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Efficiency&lt;/strong&gt; : Ratio of standard deviation of bootstrapped original weights comparing to
bootstrapped weights based on various methods described above. This is telling us how our newly estimated weights varied comparing to original weights.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Bias&lt;/strong&gt; : Difference between average bootstrapped estimates. Here, it is the difference between original weights to bootstrapped weights based on methods described above. This is telling us how different our newly estimated weights comparing to original weights.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;results&#34;&gt;&lt;strong&gt;Results&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1. Were the parameters biased?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The table below indicated that the parameter estimates were close to it&amp;rsquo;s original estimates.
&lt;img src=&#34;TableWeights.png&#34; alt=&#34;Weighted estimates comparison&#34; title=&#34;Weighted estimates comparison&#34;&gt;&lt;/p&gt;
&lt;p&gt;Also, across all the models, bias of different estimates (age, race, etc.,) were around zero.
&lt;img src=&#34;BiasLine.png&#34; alt=&#34;Weighted estimates line&#34; title=&#34;Weighted estimates comparison&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. Were the estimated weights efficient?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Here,  yg and xyg model, which was gamma modeling of unsmoothed and smoothed sampling weights had the highest efficiency in estimating weights.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;Efficiency.png&#34; alt=&#34;Efficiency of bootstrap estimates&#34; title=&#34;Weighted estimates comparison&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;While all the models used above can estimate accuracte weights, Gamma and linear models using either un-smoothed or smoothed estimates have the highest efficiency in estimating weights.&lt;/p&gt;
&lt;h2 id=&#34;resource&#34;&gt;&lt;strong&gt;Resource&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;You can find the R code to do this analysis in my github respoitory.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>What kind of words can influence our memory?</title>
      <link>https://zhouxiaojue.github.io/project/wordproperties/</link>
      <pubDate>Mon, 07 Dec 2015 14:18:55 -0800</pubDate>
      <guid>https://zhouxiaojue.github.io/project/wordproperties/</guid>
      <description>&lt;h2 id=&#34;the-problem&#34;&gt;&lt;strong&gt;The Problem&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Past studies already demonstrate strong emotional content of words improves people’s immediate recall memory and consistent colors further enhance memory(Donald et al., 2004).  It is interesting to see if same conclusion can be draw on metamemory and whether the color still interacts with emotion. If so, we can say this effect is immediate and on-line.&lt;/p&gt;
&lt;p&gt;Besides looking at people’s memory ability, we can also look at how people recognize this cognitive ability. Metacognition is “thinking of thinking”. Metamemory is the introspective cognition about one’s own memory ability. It is a self-judgment. While people’s natural memory capacity would restrain number of words actually remembered, words’ attributes may have larger effect on decision of one’s judgment of memory ability.&lt;/p&gt;
&lt;p&gt;One hypothesis of current study is participants will remember more words when words are more familiar or easier to imagine. However, participants may not consider themselves remember (metamemory) more imaginable words but they will for more familiar words, for the reason that imageability is not very easy to identify at first impression. The current paper studies how four attributes—imageability, familiarity, emotional valence and associated colors—affect people’s ability to remember words.&lt;/p&gt;
&lt;p&gt;Factorial design is an efficient way to design experiment to quickly investigate individual variable effects, as well as the ability to study interaction effects between variables. Here I will used factorial design with repeated measure to understand the following questions.&lt;/p&gt;
&lt;p&gt;Hypothesis:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;How word&amp;rsquo;s properties influence human memory ability?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How does individual word&amp;rsquo;s properties influence the differences in metacognition and recall?&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;Stimuli.png&#34; alt=&#34;Stimuli&#34; title=&#34;StimuliColor&#34;&gt;&lt;/p&gt;
&lt;div align = &#34;center&#34;&gt;Example stimuli of emotional valence and color variable. Each participant received a list of 20 words and ask to remember them. &lt;/div&gt;
&lt;h2 id=&#34;experimental-design&#34;&gt;&lt;strong&gt;Experimental Design&lt;/strong&gt;&lt;/h2&gt;
&lt;h4 id=&#34;independent-variables&#34;&gt;Independent Variables&lt;/h4&gt;
&lt;p&gt;Here I used 4X3 repeated measure design to study the following effects both individually and also their interactions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Emotional Valence&lt;/li&gt;
&lt;li&gt;Imageability&lt;/li&gt;
&lt;li&gt;Familiarity&lt;/li&gt;
&lt;li&gt;Colors&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;DesignVariables.png&#34; alt=&#34;Variables&#34; title=&#34;Variables of interest&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;design&#34;&gt;Design&lt;/h4&gt;
&lt;p&gt;Specific design here is a full factorial design. Words’ order in each list was completely randomized. Each condition was replicated three times (three blocks) and each block contained completely randomized orders of 16 trials.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;DesignMatrix.png&#34; alt=&#34;Design&#34; title=&#34;DesignMatrix&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;measurements-of-memory&#34;&gt;&lt;strong&gt;Measurements of memory&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;meta-memory&lt;/strong&gt; : number of words they think they will remember. This measured subjects&amp;rsquo;s metacognition of self memory.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;actual recall&lt;/strong&gt; : number of words actually written down correctly. This is used to compare with meta-memory.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-i-found&#34;&gt;&lt;strong&gt;What I found&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;While individual ANOVA analysis of response variable &lt;em&gt;recall&lt;/em&gt;, or &lt;em&gt;meta-cognition&lt;/em&gt; has not shown any significant effect dependent on words&#39; properties. I further only looked at words overlap between words subjects they thought they would remember, and also they actually recalled later.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;Results.png&#34; alt=&#34;Result&#34; title=&#34;Results&#34;&gt;
Here I found out three $\rho &amp;lt; 0.01$ interaction effects on the items subjects both thought they would remember, and also they actually recalled:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Imageability and familarity&lt;/li&gt;
&lt;li&gt;Imageability and colors&lt;/li&gt;
&lt;li&gt;Emotional valence and familarity&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here it indicated that more imagenable and familiar words lead to better memory and also made deeper impression both consciously (through meta-cognition) and also subconsciously (recall).&lt;/p&gt;
&lt;h4 id=&#34;participants-characteristics-by-condition&#34;&gt;&lt;strong&gt;Participants characteristics by Condition&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;I additionally analyze how the participants use to remember words.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Participants used at least one strategy (9.33) remember more than participants used no strategy at all (8.125).&lt;/li&gt;
&lt;li&gt;Most participants used strategies such as association, twist letter, phonetic clues to remember words.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;English words with following properties made more impression:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Familiar words&lt;/li&gt;
&lt;li&gt;Negative words&lt;/li&gt;
&lt;li&gt;Emotional words&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Also, words in cooler colors allowed subjects to imagine those words more easily, therefore possibly increasing their memory on those words. Additionally, using a strategy was important to recall english words.&lt;/p&gt;
&lt;h2 id=&#34;resource&#34;&gt;&lt;strong&gt;Resource&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;My code to analyze the experiment data can be found here &lt;a href=&#34;project.Rmd&#34;&gt;(R Markdown file)&lt;/a&gt; and also on my github repository. If you want to replicate this experiment yourself, here is the materials &lt;a href=&#34;wordlist.pdf&#34;&gt;(Wordlist.pdf)&lt;/a&gt; I used to conduct this experiment.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Procrastination Questionnaire Construction</title>
      <link>https://zhouxiaojue.github.io/project/procrastinatequestionnaire/</link>
      <pubDate>Sun, 07 Dec 2014 14:18:32 -0800</pubDate>
      <guid>https://zhouxiaojue.github.io/project/procrastinatequestionnaire/</guid>
      <description>&lt;h2 id=&#34;motivation&#34;&gt;&lt;strong&gt;Motivation&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Most of the procrastination questionnaire is old, and subtypes of procrastination has been definied but not applied. While most people studied anxiety behind procrastination and rather used vague questions to ask individual subjects on their patterns of daily activity. I was interested in building a questionnaire specifically targeting college students.&lt;/p&gt;
&lt;h2 id=&#34;questionnaire-construction&#34;&gt;&lt;strong&gt;Questionnaire Construction&lt;/strong&gt;&lt;/h2&gt;
&lt;h4 id=&#34;what-the-textbook-says&#34;&gt;&lt;strong&gt;What the textbook says&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;From Crocker &amp;amp; Algina&amp;rsquo;s textbook :  &lt;em&gt;Introduction to Classical and Modern Test Theory&lt;/em&gt;, they suggested the following steps when constructing a test.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Identify the primary purpose of the test score use&lt;/li&gt;
&lt;li&gt;Identify behaviors to represent the construct
&lt;ul&gt;
&lt;li&gt;content analysis&lt;/li&gt;
&lt;li&gt;review of research&lt;/li&gt;
&lt;li&gt;critical incident&lt;/li&gt;
&lt;li&gt;direct observation&lt;/li&gt;
&lt;li&gt;expert judgement&lt;/li&gt;
&lt;li&gt;instruction objectives&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Domain sampling&lt;/li&gt;
&lt;li&gt;Item construction&lt;/li&gt;
&lt;li&gt;Item review&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;how-i-wrote-the-questionnaire&#34;&gt;&lt;strong&gt;How I wrote the questionnaire&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;First of all, I want to know what it means exactly by procrastination.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. Procrastination definition&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Procrastination is the unplanned delaying tasks and procrastinators often feel guilty about their procrastination.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. Literature Research&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Then, I wanted to know if any researchers has systematically studied procrastination. So I searched studies on academic procrastination and summarized their findings on procrastination.&lt;/p&gt;
&lt;p&gt;Specifically, procrastination can be divided into two categories.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;decisional procrastination&lt;/li&gt;
&lt;li&gt;behavioral procrastination.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3. Brain Storm&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;After studying about procrastination study, then I visualized what a procrastinator (like myself) would do in each category.&lt;/p&gt;
&lt;p&gt;Typical behaviors of procrastinators are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;missing deadlines&lt;/li&gt;
&lt;li&gt;making decisions until last minutes&lt;/li&gt;
&lt;li&gt;spend time on meaningless task before finishing task&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Additionally, I included questions to ask about how individuals recognize their procrastination by asking question in these two additional categories.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;how they feel about procrastination&lt;/li&gt;
&lt;li&gt;the reasons for procrastinations&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;my-questionnaire&#34;&gt;&lt;strong&gt;My questionnaire&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;questionnaire.png&#34; alt=&#34;questionnaire&#34; title=&#34;Questionnaire&#34;&gt;
The current questionnaire is a self-evaluating scale focused on behavioral and decisional procrastinations in daily life and academic, reasons of procrastinations and feelings about procrastinations.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Initially I had 50 items, then I analyzed the collected responses and end up with 25 items.&lt;/li&gt;
&lt;li&gt;5-point likert scale&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;population-and-sample&#34;&gt;&lt;strong&gt;Population and sample&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;I collected responses from 25 classmates in my psychometric class, which are all graduate students in academics so it fits my desired academic population.&lt;/p&gt;
&lt;h2 id=&#34;measuring-my-questionnaire&#34;&gt;&lt;strong&gt;Measuring my questionnaire&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;I used the following measurements to understand how effective my questionnaire is at evaluating people&amp;rsquo;s internal states.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Cohen&amp;rsquo;s kappa&lt;/strong&gt; : Cohen&amp;rsquo;s kappa measures the agreement between two raters who each classify N items into mutually exclusive categories.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;inter-rater agreement&lt;/strong&gt; : confidence of whether the cluster I assign it to other people also assign it to.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;potential-impact&#34;&gt;&lt;strong&gt;Potential Impact&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Procrastination scores were often related to lower self-regulations, lower self-efficacy, and higher neuroctism of personality trait. While most people would recognize procrastination as part of their personality, I hope this questionnaire would be their first step to identify specific behavior pattern and their general tendency to procrastination.&lt;/p&gt;
&lt;h2 id=&#34;improvements&#34;&gt;&lt;strong&gt;Improvements&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Unfortunately, I lost the original collected data therefore cannot recover the measured statistics on individual items. This questionnaire was a psychometric class project and therefore hasn&amp;rsquo;t been widely studied in a bigger subject pool. If I have an opportunity, I would specifically collect responses from undergraduate students and see how different the response is comparing to graduate students&#39;. Also, this questionnaire was designed in 2014 and people probably procrastinate with different things with advances in technology in 2021 (2021 still sounds like future to me).&lt;/p&gt;
&lt;h2 id=&#34;resources&#34;&gt;&lt;strong&gt;Resources&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;If you are intersted in using my questionnaire, you can find the printable pdf here &lt;a href=&#34;procrastinationscale.pdf&#34;&gt;(Procrastination Survey)&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How speaking a different language influneces our semantic understanding</title>
      <link>https://zhouxiaojue.github.io/project/chineseword/</link>
      <pubDate>Fri, 07 Feb 2014 14:18:03 -0800</pubDate>
      <guid>https://zhouxiaojue.github.io/project/chineseword/</guid>
      <description>&lt;h2 id=&#34;what-we-want&#34;&gt;&lt;strong&gt;What we want&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&#34;the-problem&#34;&gt;&lt;strong&gt;The problem&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;FlowerAll.jpg&#34; alt=&#34;Flowers&#34; title=&#34;All Flowers belong to flower category&#34;&gt;&lt;/p&gt;
&lt;p&gt;In English, individual flowers are usually named with specific name of that flower (e.g., rose, tulip). However, in Chinese flowers are usually named by both the basic level name (e.g., rose, tulip) followed by subordinate level name (花, flower). For example, chamomile is named 菊花 or chamomile flower. Therefore, it&amp;rsquo;s possible that Chinese native speakers categorize daily objects differently because how Chinese has built-in category information in the language.&lt;/p&gt;
&lt;p&gt;Here, we are interested in finding the priming effects of the language. First of all, we need a standardized bank of based on Chinese speakers in order to find the most representable objects inside each basic levle category (e.g., a typical dog species within dog, typical flower within flower)&lt;/p&gt;
&lt;h2 id=&#34;what-we-had&#34;&gt;&lt;strong&gt;What We Had&lt;/strong&gt;&lt;/h2&gt;
&lt;h4 id=&#34;a-bank-of-stimuli&#34;&gt;A bank of stimuli&lt;/h4&gt;
&lt;p&gt;First, we collected a bank of stimuli using daily objects. In the table below, each row is an picture representing a daily object. We want to know on average, if each item is named correctly and also consistenty among all the subjects.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;DesiredOutcome.png&#34; alt=&#34;Desired bank of stimuli&#34; title=&#34;Desired bank of stimuli&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;design-experiment-to-observe-verbal-response&#34;&gt;Design experiment to observe verbal response&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;goldRetriever.jpeg&#34; alt=&#34;Stimuli&#34; title=&#34;Example stimuli&#34;&gt;&lt;/p&gt;
&lt;div align = &#34;center&#34;&gt;An example stimuli&lt;/div&gt;
&lt;p&gt;&lt;img src=&#34;Response.png&#34; alt=&#34;Response&#34; title=&#34;Response of stimuli&#34;&gt;&lt;/p&gt;
&lt;p&gt;In the experiment, we asked each subject to name a total of 400 individual pictures of objects and collected over 30 subjects&#39; verbal response to each picture, as well as how fast they name the object.&lt;/p&gt;
&lt;h4 id=&#34;measurements-of-individual-items&#34;&gt;Measurements of individual items&lt;/h4&gt;
&lt;p&gt;For each item (picture), we calculated the following statistics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Entropy&lt;/li&gt;
&lt;li&gt;Average naming accuracy&lt;/li&gt;
&lt;li&gt;Total number of different labels&lt;/li&gt;
&lt;li&gt;Average response time&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;what-we-found&#34;&gt;&lt;strong&gt;What We Found&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;While this is still an ongoing project, we have established the bank of 285 individual pictures of daily animals and daily objects, each comes with the following information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Standardized Chinese name&lt;/li&gt;
&lt;li&gt;Corresponding English names&lt;/li&gt;
&lt;li&gt;Item&amp;rsquo;s basic semantic level&lt;/li&gt;
&lt;li&gt;Item&amp;rsquo;s surordinate level&lt;/li&gt;
&lt;li&gt;Average Response time&lt;/li&gt;
&lt;li&gt;Entropy&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;future&#34;&gt;&lt;strong&gt;Future&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;If you are interested in collaboration, please contact halleycl at gmail dot com. We would love to have people use this stimuli bank!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://zhouxiaojue.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://zhouxiaojue.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
